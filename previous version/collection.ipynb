{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tweepy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: demoji in ./venv/lib/python3.9/site-packages (0.4.0)\r\n",
      "Requirement already satisfied: requests<3.0.0 in ./venv/lib/python3.9/site-packages (from demoji) (2.25.1)\r\n",
      "Requirement already satisfied: colorama in ./venv/lib/python3.9/site-packages (from demoji) (0.4.4)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.9/site-packages (from requests<3.0.0->demoji) (2021.5.30)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./venv/lib/python3.9/site-packages (from requests<3.0.0->demoji) (1.26.5)\r\n",
      "Requirement already satisfied: idna<3,>=2.5 in ./venv/lib/python3.9/site-packages (from requests<3.0.0->demoji) (2.10)\r\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in ./venv/lib/python3.9/site-packages (from requests<3.0.0->demoji) (4.0.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install demoji\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: demoji in ./venv/lib/python3.9/site-packages (0.4.0)\n",
      "Requirement already satisfied: colorama in ./venv/lib/python3.9/site-packages (from demoji) (0.4.4)\n",
      "Requirement already satisfied: requests<3.0.0 in ./venv/lib/python3.9/site-packages (from demoji) (2.25.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.9/site-packages (from requests<3.0.0->demoji) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./venv/lib/python3.9/site-packages (from requests<3.0.0->demoji) (1.26.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in ./venv/lib/python3.9/site-packages (from requests<3.0.0->demoji) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in ./venv/lib/python3.9/site-packages (from requests<3.0.0->demoji) (4.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install demoji\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: emoji in ./venv/lib/python3.9/site-packages (1.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "preprocess-twitter.py\n",
    "\n",
    "python preprocess-twitter.py \"Some random text with #hashtags, @mentions and http://t.co/kdjfkdjf (links). :)\"\n",
    "\n",
    "Script for preprocessing tweets by Romain Paulus\n",
    "with small modifications by Jeffrey Pennington\n",
    "with translation to Python by Motoki Wu\n",
    "\n",
    "Translation of Ruby script to create features for GloVe vectors for Twitter data.\n",
    "http://nlp.stanford.edu/projects/glove/preprocess-twitter.rb\n",
    "\"\"\"\n",
    "\n",
    "import regex as re\n",
    "import tweepy\n",
    "\n",
    "FLAGS = re.MULTILINE | re.DOTALL\n",
    "\n",
    "\n",
    "def aggregateUpper(hashtag_list):\n",
    "    hashtag_list_copy = hashtag_list\n",
    "    length = [len(i) for i in hashtag_list_copy]\n",
    "    if length[0]==0:\n",
    "        hashtag_list_copy.pop(0)\n",
    "        length.pop(0) \n",
    "    change = True\n",
    "    try:\n",
    "        while change:\n",
    "            pos = length.index(1)\n",
    "            if length[pos+1]==1:\n",
    "                hashtag_list_copy[pos] = hashtag_list_copy[pos]+hashtag_list_copy[pos+1]\n",
    "                hashtag_list_copy.pop(pos+1)\n",
    "                length.pop(pos+1)\n",
    "                change = True\n",
    "            else:\n",
    "                change = False\n",
    "    except:\n",
    "        pass\n",
    "    return hashtag_list_copy\n",
    "\n",
    "def hashtag(text):\n",
    "    text = text.group()\n",
    "    hashtag_body = text[1:]\n",
    "    if hashtag_body.isupper():\n",
    "        result = \" {} \".format(hashtag_body.lower())\n",
    "    else:\n",
    "        result = \" \".join([\"<hashtag>\"] + aggregateUpper(re.split(r\"(?=[A-Z])\", hashtag_body, flags=FLAGS)))  # add aggregateUpper Function\n",
    "    return result\n",
    "    \n",
    "def allcaps(text):\n",
    "    text = text.group()\n",
    "    return text.lower() + \" <allcaps>\"\n",
    "\n",
    "def tokenize(text):\n",
    "    # Different regex parts for smiley faces\n",
    "    eyes = r\"[8:=;]\"\n",
    "    nose = r\"['`\\-]?\"\n",
    "\n",
    "    # function so code less repetitive\n",
    "    def re_sub(pattern, repl):\n",
    "        return re.sub(pattern, repl, text, flags=FLAGS)\n",
    "\n",
    "    text = re_sub(r\"https?:\\/\\/\\S+\\b|www\\.(\\w+\\.)+\\S*\", \"<url>\")\n",
    "    text = re_sub(r\"@\\w+\", '<user>')\n",
    "    # text = re_sub(r\"{}{}[)dD]+|[)dD]+{}{}\".format(eyes, nose, nose, eyes), \"<smile>\")\n",
    "    # text = re_sub(r\"{}{}p+\".format(eyes, nose), \"<lolface>\")\n",
    "    # text = re_sub(r\"{}{}\\(+|\\)+{}{}\".format(eyes, nose, nose, eyes), \"<sadface>\")\n",
    "    # text = re_sub(r\"{}{}[\\/|l*]\".format(eyes, nose), \"<neutralface>\")\n",
    "    text = re_sub(r\"/\",\" / \")\n",
    "    # text = re_sub(r\"<3\",\"<heart>\")\n",
    "   # text = re_sub(r\"[-+]?[.\\d]*[\\d]+[:,.\\d]*\", \"<number>\") # defunction number\n",
    "    text = re_sub(r\"#\\S+\", hashtag)\n",
    "    text = re_sub(r\"([!?.]){2,}\", r\"\\1 <repeat>\")\n",
    "    text = re_sub(r\"\\b(\\S*?)(.)\\2{2,}\\b\", r\"\\1\\2 <elong>\")\n",
    "\n",
    "    ## -- I just don't understand why the Ruby script adds <allcaps> to everything so I limited the selection.\n",
    "    # text = re_sub(r\"([^a-z0-9()<>'`\\-]){2,}\", allcaps)\n",
    "    # text = re_sub(r\"([A-Z]){2,}\", allcaps)   # defunction <allcap>\n",
    "\n",
    "    return text.lower()\n",
    "\n",
    "def get_keys():\n",
    "    keys = {}\n",
    "    with open(\"apikeys.txt\") as f:\n",
    "        api_key = f.read().split(\"\\n\")\n",
    "    keys['consumer key'] = api_key[0]\n",
    "    keys['consumer secret'] = api_key[1]\n",
    "    keys['access token'] = api_key[2]\n",
    "    keys['access token secret'] = api_key[3]\n",
    "    return keys\n",
    "\n",
    "\n",
    "\n",
    "def domain(url):\n",
    "    pattern = r\"https?://([\\w.-]+)/?\"\n",
    "    match = re.search(pattern, url)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return\n",
    "\n",
    "def initialize_api():\n",
    "    keys = get_keys()\n",
    "    auth = tweepy.OAuthHandler(keys['consumer key'], keys['consumer secret'])\n",
    "    auth.set_access_token(keys['access token'], keys['access token secret'])\n",
    "    api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)\n",
    "    return api\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading emoji data ...\n",
      "... OK (Got response in 0.23 seconds)\n",
      "Writing emoji data to /Users/hawhee/.demoji/codes.json ...\n",
      "... OK\n",
      "Python version: 3.9.2\n"
     ]
    }
   ],
   "source": [
    "import pymongo\n",
    "import regex as re\n",
    "from datetime import datetime, date, timedelta\n",
    "import demoji\n",
    "import emoji\n",
    "demoji.download_codes()\n",
    "\n",
    "import tweepy\n",
    "from platform import python_version\n",
    "print(\"Python version:\", python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveToMongo(collection, document):\n",
    "    col = db[collection]\n",
    "    col.insert_one(document)\n",
    "\n",
    "def clearEntireCollection(collection):\n",
    "    col = db[collection]\n",
    "    col.delete_many({})\n",
    "    \n",
    "def domain(url):\n",
    "    pattern = r\"https?://([\\w.-]+)/?\"\n",
    "    match = re.search(pattern, url)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return\n",
    "    \n",
    "    \n",
    "def tranform_tweets(tweet, collection):\n",
    "    hashtags, mentions, urls, urlDomains, emojis = [], [], [], [], []\n",
    "            \n",
    "    time = tweet.created_at\n",
    "    tweetID = tweet.id_str\n",
    "    userID = tweet.user.id_str\n",
    "    screenName = tweet.user.screen_name\n",
    "    text = tweet.full_text\n",
    "\n",
    "    # preprocessing\n",
    "    emojis.extend(demoji.findall(text).keys())\n",
    "    text2 = demoji.replace(text,'')\n",
    "    textPrep = tokenize(text2)\n",
    "\n",
    "    try:\n",
    "        isoLanguage = tweet.metadata[\"iso_language_code\"]\n",
    "    except:\n",
    "        isoLanguage = None\n",
    "    favoriteCount = tweet.favorite_count\n",
    "    retweetCount = tweet.retweet_count\n",
    "#   replyCount = tweet.reply_count                      # Premium API Only\n",
    "    location = tweet.user.location                        # Location on the user profile\n",
    "    if tweet.place:\n",
    "        placeName = tweet.place.full_name                     # Place of the post that is tagged with\n",
    "        placeCountry = tweet.place.country_code \n",
    "    else:\n",
    "        placeName = None\n",
    "        placeCountry = None\n",
    "    followersCount = tweet.user.followers_count\n",
    "\n",
    "    # unwraping\n",
    "    hashtags_tweepy = tweet.entities['hashtags'] \n",
    "    mentions_tweepy = tweet.entities['user_mentions']\n",
    "    urls_tweepy = tweet.entities['urls']\n",
    "    for hashtag in hashtags_tweepy: \n",
    "        hashtags.append(hashtag['text'].lower()) \n",
    "    for user in mentions_tweepy: \n",
    "        mentions.append(user['screen_name']) \n",
    "    for url in urls_tweepy: \n",
    "        urls.append(url['expanded_url'].lower())\n",
    "        urlDomains.append(domain(url['expanded_url'].lower()))\n",
    "\n",
    "    document = {\n",
    "        \"time\": time,\n",
    "        \"tweetID\": tweetID,\n",
    "        \"userID\": userID,\n",
    "        \"screenName\": screenName,\n",
    "        \"text\": text,\n",
    "        \"emojis\": emojis,\n",
    "        \"textPrep\": textPrep,\n",
    "        \"isoLanguage\": isoLanguage,\n",
    "        \"favoriteCount\": favoriteCount,\n",
    "        \"retweetCount\": retweetCount,\n",
    "        \"location\": location,\n",
    "        \"placeName\": placeName,\n",
    "        \"placeCountry\": placeCountry,\n",
    "        \"followersCount\": followersCount,\n",
    "        \"hashtags\": hashtags,\n",
    "        \"mentions\": mentions,\n",
    "        \"urls\": urls,\n",
    "        \"urlDomains\": urlDomains\n",
    "    }\n",
    "\n",
    "    saveToMongo(collection, document)\n",
    "    return userID\n",
    "\n",
    "\n",
    "def tranform_users(tweet, user_collection):\n",
    "    userID = tweet.user.id_str\n",
    "    name = tweet.user.name\n",
    "    screenName = tweet.user.screen_name\n",
    "    location = tweet.user.location\n",
    "    description = tweet.user.description\n",
    "    following = tweet.user.friends_count\n",
    "    follower = tweet.user.followers_count\n",
    "    favorite = tweet.user.favourites_count\n",
    "    status = tweet.user.statuses_count\n",
    "    profile_image_url = tweet.user.profile_image_url\n",
    "\n",
    "    document2 = {\n",
    "            \"userID\": userID,\n",
    "            \"name\": name,\n",
    "            \"screenName\": screenName,\n",
    "            \"location\": location,\n",
    "            \"description\": description,\n",
    "            \"following\": following,\n",
    "            \"follower\": follower,\n",
    "            \"favorite\": favorite,\n",
    "            \"status\": status,\n",
    "            \"profile_image_url\": profile_image_url\n",
    "        }\n",
    "    saveToMongo(user_collection, document2)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def search_tweets(api, collection, query, since, until, user_collection=None, place_id=None):\n",
    "    if place_id:\n",
    "        q = query + f\" since:{since} until:{until}\" + \" -filter:retweets AND -filter:replies\" + f\" AND place:{place_id}\"\n",
    "        print(f\"Start Collecting Query: {q}\")\n",
    "    else:\n",
    "        q = query + f\" since:{since} until:{until}\" + \" -filter:retweets AND -filter:replies\"\n",
    "        print(f\"Start Collecting Query: {q}\")\n",
    "    \n",
    "    \n",
    "    count_ = 0\n",
    "    print(f\"Time of now: {datetime.now()}\")\n",
    "    \n",
    "    \n",
    "    for tweet in tweepy.Cursor(api.search, q=q, lang = \"en\", tweet_mode=\"extended\").items(30):\n",
    "        count_ += 1\n",
    "        if count_%100 == 0:\n",
    "            print(f\"Have collecte {count_} tweets! - {datetime.now()}\")\n",
    "\n",
    "        # check if this tweet is already in the database\n",
    "        if db[collection].find_one({\"tweetID\": tweet.id_str}):\n",
    "            continue\n",
    "        else:\n",
    "            userID = tranform_tweets(tweet, collection)\n",
    "            \n",
    "            # check if this user is already in the database\n",
    "            if db[user_collection].find_one({\"userID\": userID}):\n",
    "                continue\n",
    "            else:\n",
    "                tranform_users(tweet, user_collection)\n",
    "                # Users' tweets: Only scrape at most 100 tweets or the tweets within 6 months (180 days)\n",
    "                for tweet in tweepy.Cursor(api.user_timeline,id=userID, tweet_mode='extended').items(100):\n",
    "                    created = tweet.created_at\n",
    "                    if (created < datetime.now() - timedelta(days=180)) or (db[collection].find_one({\"tweetID\": tweet.id_str})):\n",
    "                        break\n",
    "                    else:\n",
    "                        tranform_tweets(tweet, collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = get_keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['taccounts', 'users', 'tweets']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Connect to mongoDB\n",
    "client = pymongo.MongoClient(mongoDB_connection)\n",
    "db = client[database_name]\n",
    "db.list_collection_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Connect to Twitter API\n",
    "api = initialize_api()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collect data with keywords BLM from 2021-06-19 to 2021-06-20 in United States(96683cc9126741d1)\n",
      "Data collected will be put into collection tweets\n"
     ]
    }
   ],
   "source": [
    "### Search filters\n",
    "collection = \"tweets\"\n",
    "user_collection = \"taccounts\"\n",
    "query = \"BLM\"\n",
    "since = str(date.today()-timedelta(days=3))\n",
    "until = str(date.today()-timedelta(days=2))\n",
    "searchCountry = \"United States\"\n",
    "\n",
    "places = api.geo_search(query=searchCountry, granularity=\"country\")\n",
    "for place in places:\n",
    "    if place.full_name == searchCountry:\n",
    "        place_obj = place\n",
    "        place_id = place.id\n",
    "        \n",
    "print(f\"Collect data with keywords {query} from {since} to {until} in {place_obj.name}({place_id})\")\n",
    "print(f\"Data collected will be put into collection {collection}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Collecting\n",
    "# search_tweets(api, collection, query, since, until, place_id # with specifc location\n",
    "search_tweets(api, collection, query, since, until, user_collection=user_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Documents:\",db[collection].count_documents({}))\n",
    "print(\"Documents:\",db[user_collection].count_documents({}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "db[collection].find_one({\"time\":{\"$lt\":datetime(2021,5,30,0,0,0)}})\n",
    "# db[collection].find_one({\"favoriteCount\":{\"$gt\":1}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Cleaning\n",
    "clearEntireCollection(\"tweets\")\n",
    "print(db.tweets.find_one()) #check if it is empty"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
